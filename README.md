# SteamGamesRecommender

Capstone Project Report
BrainStation
Steven Kies
Project Statement
Steam Games has tens of thousands of games available. Learning how those games are distributed would aid in several applications. But the features those games have number in the hundreds, so clustering the games by a set of features would make categorizing them easier. My eventual goal is to find the optimal number of clusters and their descriptions. These clusters could then be used to create various models. The next step would be to use user preferences to build a recommendation system. The business use of this exploration would be to increase sales by making game recommendations to users that they would be more likely to like.
Subject Background
There are three reasons PCA and clustering are important techniques in data science. Firstly, reducing the dimensionality of the data is useful when there are many features. High- dimensionality if difficult to interpret, so reducing it, while preserving the information, in terms of variability, is valuable. Clustering also helps uncover structure within the dataset. There is no guarantee that the available variables are independent and capture key factors in the structure. Pooling the feature information may give a better representation. Finally, Clustering helps with predictive tasks. A predictive model is only as good as the data it is modeled on, so extracting as much of the underlying structure makes the model optimal.
Dataset Details
The dataset is composed of four tables. Both datasets were taken from Kaggle and were collected from the Steam API in 2022. One is a collection of three datasets (https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam): games, users, and recommendations. The games table contains information on the games which are available on Steam Games. The users dataset contains information on the users who gave the recommendations and the recommendations dataset gives the recommendation the user gave for a particular game. A second dataset (https://www.kaggle.com/datasets/tristan581/all-55000-games-on-steam-november-2022) consists of only one table, which contains descriptive details on the games available on Steam games. This dataset was used because the first dataset did not include this important information.
Cleaning & Preprocessing
After creating four dataframes from the tables of the datasets, they were merged on the app_id and user_id where appropriate. The duplicate columns were then removed. Any rows with NaNs were removed from the merged dataframe. This left 553 unique games and over 5 million users, and a total of around 8 million rows. To reduce the number of rows in the dataset, only those users who made the most recommendations were used. This resulted in around 600000 rows. Since the process of cleaning the dataset was intensive, the dataframe was saved for further use. Vectorizing the Genres, Short Description and Categories columns was cumbersome. A more direct method was vectorizing the user assigned tags, where instead of a binary value, the value was the ratio of users who assigned that tag to a game. It was found that there was a 0.80 ratio of positive to negative recommendations, so the dataframe was balanced so that 100000 positive and 100000 negative recommendations were included.  Irrelevant columns, such as the website, user id and app id were removed to produce the final dataframe. All Modelling was done using this final dataframe. Trying to use PCA was not effective, as the result was loading values of 0. The most expedient choice was to perform feature selection using SelectKBest and f_classif. This led to increased model accuracies and faster computation times.
Insights, Modeling & Results
Logistic regression, SVD, and XGBoost models of the dataframe resulted in accuracy levels at change. About 50%. Rerunning the models with the top 10 features saw a modest increase in performance, 54 to 58% depending on the model. The ROC plots were also smoother.
Findings & Conclusion
Computation time severely restricted what could be done, so accuracy was very low. There are indications that feature engineering, by limiting the number of features in the dataset, increases model accuracy. With more computational power, it may be that PCA or KMeans clustering would also cause a significant increase in model performance, if the entire original dataset were used. A next step would be to attempt this with cloud computing. Beyond this, the results could be used to build a game recommendation system based on user preferences and purchase history.
